{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ h_{out} = \\frac{1}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolucional Neuronal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/juangomez/Desktop/ML/Cursos/Pepe Cantoral/datasets'\n",
    "num_train = 50000\n",
    "num_val = 5000\n",
    "num_test = 5000\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "transform_cifar = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.491, 0.482, 0.447], [0.247, 0.243, 0.261])\n",
    "])\n",
    "\n",
    "# Training set\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_cifar)\n",
    "train_loader = DataLoader(\n",
    "    cifar10_train,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler.SubsetRandomSampler(range(num_train)))\n",
    "\n",
    "# Validation set\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train= False,\n",
    "    download=True,\n",
    "    transform=transform_cifar)\n",
    "val_loader = DataLoader(\n",
    "    cifar10_val,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler.SubsetRandomSampler(range(num_val)))\n",
    "\n",
    "# Test set\n",
    "cifar10_test = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform= transform_cifar)\n",
    "test_loader = DataLoader(\n",
    "    cifar10_test,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler.SubsetRandomSampler(range(num_test, num_test + num_val))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# this make a generator\n",
    "data_iter = iter(train_loader)\n",
    "# get the first batch\n",
    "images, labels = next(data_iter)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show the image 0 of the batch 7. Class: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "def plot_figure(image):\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "idx= np.random.randint(len(test_loader))\n",
    "print(f'Show the image 0 of the batch {idx}. Class: ')\n",
    "image = test_loader.dataset[idx][0]\n",
    "image = (image- image.min())/(image.max()-image.min())\n",
    "plot_figure(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for xi, yi in loader:\n",
    "            xi = xi.to(device)\n",
    "            yi = yi.to(device)\n",
    "            scores = model(xi)\n",
    "            # Compute the max in each row for each image of the batch\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == yi).sum()\n",
    "            num_total += len(yi)\n",
    "        return float(num_correct) / num_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=100):\n",
    "    model = model.to(device = device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for (xi, yi) in train_loader:\n",
    "            xi = xi.to(device = device, dtype=torch.float32)\n",
    "            yi = yi.to(device = device, dtype=torch.long)\n",
    "            scores = model(xi)\n",
    "\n",
    "            cost = F.cross_entropy(input=scores, target=yi.squeeze())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "        acc = accuracy(model, val_loader)\n",
    "        if epoch%1 == 0:\n",
    "            print(f'Epoch {epoch}, Cost: {cost.item()}, accuracy: {acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secuential linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 1.4126169681549072, accuracy: 0.3842\n",
      "Epoch 1, Cost: 1.751052737236023, accuracy: 0.4476\n",
      "Epoch 2, Cost: 1.5607020854949951, accuracy: 0.4568\n",
      "Epoch 3, Cost: 1.5625749826431274, accuracy: 0.5054\n",
      "Epoch 4, Cost: 1.1747633218765259, accuracy: 0.5176\n",
      "Epoch 5, Cost: 1.312883973121643, accuracy: 0.5238\n",
      "Epoch 6, Cost: 1.3143444061279297, accuracy: 0.5248\n",
      "Epoch 7, Cost: 0.93155837059021, accuracy: 0.5424\n",
      "Epoch 8, Cost: 1.0614793300628662, accuracy: 0.5314\n",
      "Epoch 9, Cost: 0.6877937316894531, accuracy: 0.5404\n"
     ]
    }
   ],
   "source": [
    "hidden1 = 256\n",
    "hidden2 = 256\n",
    "lr = 1e-3\n",
    "epochs = 10\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features = 3*32*32, out_features=hidden1), nn.ReLU(),\n",
    "    nn.Linear(in_features = hidden1, out_features=hidden2), nn.ReLU(),\n",
    "    nn.Linear(in_features = hidden2, out_features=10), nn.ReLU()\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas= (0.9, 0.999))\n",
    "train(model, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequetial CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 1.190395712852478, accuracy: 0.6196\n",
      "Epoch 1, Cost: 0.6175928711891174, accuracy: 0.6568\n",
      "Epoch 2, Cost: 0.9208447933197021, accuracy: 0.668\n",
      "Epoch 3, Cost: 0.5663272142410278, accuracy: 0.6658\n",
      "Epoch 4, Cost: 0.7299443483352661, accuracy: 0.671\n",
      "Epoch 5, Cost: 0.7757601141929626, accuracy: 0.669\n",
      "Epoch 6, Cost: 1.0843104124069214, accuracy: 0.6644\n",
      "Epoch 7, Cost: 0.6079903841018677, accuracy: 0.66\n",
      "Epoch 8, Cost: 0.2677011489868164, accuracy: 0.658\n",
      "Epoch 9, Cost: 0.6290624737739563, accuracy: 0.659\n"
     ]
    }
   ],
   "source": [
    "channel1 = 16\n",
    "channel2 = 32\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "modelCNN1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=channel1, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=channel1, out_channels=channel2, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(modelCNN1.parameters(), lr=lr, betas= (0.9, 0.999))\n",
    "train(modelCNN1, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test: 0.646\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(modelCNN1, test_loader)\n",
    "print(f'Accuracy test: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_class1(nn.Module):\n",
    "    def __init__(self, in_channels, channel1, channel2):\n",
    "        super(CNN_class1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=channel1, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=channel1, out_channels=channel2, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 1.1882120370864868, accuracy: 0.6226\n",
      "Epoch 1, Cost: 1.7210500240325928, accuracy: 0.6624\n",
      "Epoch 2, Cost: 0.6148368716239929, accuracy: 0.6738\n",
      "Epoch 3, Cost: 0.28657543659210205, accuracy: 0.6816\n",
      "Epoch 4, Cost: 0.41394874453544617, accuracy: 0.6698\n",
      "Epoch 5, Cost: 0.37266805768013, accuracy: 0.6668\n",
      "Epoch 6, Cost: 1.093558430671692, accuracy: 0.6686\n",
      "Epoch 7, Cost: 0.5645772814750671, accuracy: 0.669\n",
      "Epoch 8, Cost: 0.39643940329551697, accuracy: 0.658\n",
      "Epoch 9, Cost: 0.3360040783882141, accuracy: 0.6652\n"
     ]
    }
   ],
   "source": [
    "channel1 = 16\n",
    "channel2 = 32\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "modelCNN2 = CNN_class1(in_channels=3, channel1=channel1, channel2=channel2)\n",
    "optimizer = torch.optim.Adam(modelCNN2.parameters(), lr=lr, betas= (0.9, 0.999))\n",
    "train(modelCNN2, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test: 0.647\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(modelCNN2, test_loader)\n",
    "print(f'Accuracy test: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A little more elegant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_k_3 = lambda channel1, channel2: nn.Conv2d(in_channels=channel1, out_channels=channel2, kernel_size=3, stride=1, padding=1)\n",
    "class CNN_class2(nn.Module):\n",
    "    def __init__(self, in_channels, channel1, channel2):\n",
    "        super(CNN_class2, self).__init__()\n",
    "        self.conv1 = conv_k_3(in_channels, channel1)\n",
    "        nn.init.kaiming_uniform_(self.conv1.weight)\n",
    "        self.conv2 = conv_k_3(channel1, channel2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.7606487274169922, accuracy: 0.6262\n",
      "Epoch 1, Cost: 0.8576793074607849, accuracy: 0.6704\n",
      "Epoch 2, Cost: 0.2783229947090149, accuracy: 0.6776\n",
      "Epoch 3, Cost: 0.5572323203086853, accuracy: 0.6852\n",
      "Epoch 4, Cost: 0.8928136825561523, accuracy: 0.6682\n",
      "Epoch 5, Cost: 1.004603624343872, accuracy: 0.6726\n",
      "Epoch 6, Cost: 1.216575264930725, accuracy: 0.676\n",
      "Epoch 7, Cost: 0.27358055114746094, accuracy: 0.6638\n",
      "Epoch 8, Cost: 0.48827487230300903, accuracy: 0.6616\n",
      "Epoch 9, Cost: 0.5480047464370728, accuracy: 0.6486\n"
     ]
    }
   ],
   "source": [
    "channel1 = 16\n",
    "channel2 = 32\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "modelCNN3 = CNN_class2(in_channels=3, channel1=channel1, channel2=channel2)\n",
    "optimizer = torch.optim.Adam(modelCNN3.parameters(), lr=lr, betas= (0.9, 0.999))\n",
    "train(modelCNN3, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_k_3 = lambda channel1, channel2: nn.Conv2d(in_channels=channel1, out_channels=channel2, kernel_size=3, stride=1, padding=1)\n",
    "class CNN_class3(nn.Module):\n",
    "    def __init__(self, in_channels, channel1, channel2):\n",
    "        super(CNN_class3, self).__init__()\n",
    "        \n",
    "        self.conv1 = conv_k_3(in_channels, channel1)\n",
    "        self.bn1 = nn.BatchNorm2d(channel1)\n",
    "\n",
    "        self.conv2 = conv_k_3(channel1, channel2)\n",
    "        self.bn2 = nn.BatchNorm2d(channel2)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 1.0528945922851562, accuracy: 0.588\n",
      "Epoch 1, Cost: 0.9546079039573669, accuracy: 0.6432\n",
      "Epoch 2, Cost: 1.220665693283081, accuracy: 0.674\n",
      "Epoch 3, Cost: 0.6940227150917053, accuracy: 0.673\n",
      "Epoch 4, Cost: 0.666777491569519, accuracy: 0.6634\n",
      "Epoch 5, Cost: 0.5250480771064758, accuracy: 0.6884\n",
      "Epoch 6, Cost: 1.1143407821655273, accuracy: 0.6806\n",
      "Epoch 7, Cost: 0.8966401219367981, accuracy: 0.6876\n",
      "Epoch 8, Cost: 0.7281394600868225, accuracy: 0.6724\n",
      "Epoch 9, Cost: 0.24208472669124603, accuracy: 0.6762\n"
     ]
    }
   ],
   "source": [
    "channel1 = 16\n",
    "channel2 = 32\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "modelCNN4 = CNN_class3(in_channels=3, channel1=channel1, channel2=channel2)\n",
    "optimizer = torch.optim.Adam(modelCNN4.parameters(), lr=lr, betas= (0.9, 0.999))\n",
    "train(modelCNN4, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING POO and Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_k_3 = lambda channel1, channel2: nn.Conv2d(in_channels=channel1, out_channels=channel2, kernel_size=3, stride=1, padding=1)\n",
    "class CNN_class4(nn.Module):\n",
    "    def __init__(self, in_channels, channel1, channel2):\n",
    "        super(CNN_class4, self).__init__()\n",
    "        \n",
    "        self.conv1 = conv_k_3(in_channels, channel1)\n",
    "        self.bn1 = nn.BatchNorm2d(channel1)\n",
    "\n",
    "        self.conv2 = conv_k_3(channel1, channel2)\n",
    "        self.bn2 = nn.BatchNorm2d(channel2)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # self.flatten = nn.Flatten()\n",
    "        # self.fc = nn.Linear(in_features=16*16*channel2, out_features=10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 1.2154837846755981, accuracy: 0.6316\n",
      "Epoch 1, Cost: 0.9955135583877563, accuracy: 0.7136\n",
      "Epoch 2, Cost: 0.9092562794685364, accuracy: 0.7098\n",
      "Epoch 3, Cost: 0.30186161398887634, accuracy: 0.7462\n",
      "Epoch 4, Cost: 0.80680912733078, accuracy: 0.7704\n",
      "Epoch 5, Cost: 0.5231899619102478, accuracy: 0.7828\n",
      "Epoch 6, Cost: 1.3443899154663086, accuracy: 0.755\n",
      "Epoch 7, Cost: 0.16051079332828522, accuracy: 0.7784\n",
      "Epoch 8, Cost: 0.1875312626361847, accuracy: 0.7794\n",
      "Epoch 9, Cost: 0.263700395822525, accuracy: 0.7792\n"
     ]
    }
   ],
   "source": [
    "channel1 = 16\n",
    "channel2 = 32\n",
    "channel3 = 64\n",
    "channel4 = 128\n",
    "\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "modelCNN5 = nn.Sequential(\n",
    "    CNN_class4(in_channels=3, channel1=channel1, channel2=channel2),\n",
    "    CNN_class4(in_channels=channel2, channel1=channel3, channel2=channel4),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=8*8*channel4, out_features=10),\n",
    "    \n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(modelCNN5.parameters(), lr=lr, betas= (0.9, 0.999))\n",
    "train(modelCNN5, optimizer, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entornoJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
