{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here all the imports for importing the data and plotting the data\n",
    "import kagglehub\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/juangomez/.cache/kagglehub/datasets/hojjatk/mnist-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"hojjatk/mnist-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (50000, 784)\n",
      "Train labels shape: (50000, 1)\n",
      "Validation images shape: (10000, 784)\n",
      "Validation labels shape: (10000, 1)\n",
      "Test images shape: (10000, 784)\n",
      "Test labels shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "def load_idx(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return data\n",
    "\n",
    "# load train images\n",
    "x_train = load_idx(os.path.join(path, \"train-images.idx3-ubyte\"))[16:].reshape(60000, -1)\n",
    "y_train = load_idx(os.path.join(path, \"train-labels.idx1-ubyte\"))[8:].reshape(60000, 1)\n",
    "\n",
    "# load test images\n",
    "x_test = load_idx(os.path.join(path, \"t10k-images.idx3-ubyte\"))[16:].reshape(10000, -1)\n",
    "y_test = load_idx(os.path.join(path, \"t10k-labels.idx1-ubyte\"))[8:].reshape(10000, 1)\n",
    "\n",
    "# Get val images\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "print(\"Train images shape:\", x_train.shape)\n",
    "print(\"Train labels shape:\", y_train.shape)\n",
    "print(\"Validation images shape:\", x_val.shape)\n",
    "print(\"Validation labels shape:\", y_val.shape)\n",
    "print(\"Test images shape:\", x_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image label [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plt_image(image):\n",
    "    plt.imshow(image.reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "\n",
    "image1 = x_train[0]\n",
    "label1 = y_train[0]\n",
    "print(f'Image label {label1}')\n",
    "plt_image(image1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeImage(x_data):\n",
    "    x_mean = np.mean(x_data)\n",
    "    x_std = np.std(x_data)\n",
    "    return (x_data - x_mean) / x_std\n",
    "\n",
    "\n",
    "x_train = normalizeImage(x_train)\n",
    "x_val = normalizeImage(x_val)\n",
    "x_test= normalizeImage(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(x, y, batch_size, shuffle= True):\n",
    "    len_data = len(x)\n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(len_data)\n",
    "        x = x[idx]\n",
    "        y = y[idx]\n",
    "    return [(x[i:i+batch_size], y[i:i+batch_size]) for i in range(0, len_data, batch_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert NumpyArray â†’ torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train.copy()).to(dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test.copy()).to(dtype=torch.float32)\n",
    "x_val_tensor = torch.tensor(x_val.copy()).to(dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.copy())\n",
    "y_test_tensor = torch.tensor(y_test.copy())\n",
    "y_val_tensor = torch.tensor(y_val.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "torch.Size([10000, 784])\n",
      "torch.Size([10000, 784])\n",
      "torch.Size([50000, 1])\n",
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tensor.shape)\n",
    "print(x_test_tensor.shape)\n",
    "print(x_val_tensor.shape)\n",
    "\n",
    "print(y_train_tensor.shape)\n",
    "print(y_test_tensor.shape)\n",
    "print(y_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"We are using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y, mb_size):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.eval()\n",
    "    model = model.to(device= device)\n",
    "    with torch.no_grad():\n",
    "        for (xi, yi) in create_minibatches(x, y, mb_size):\n",
    "            xi = xi.to(device = device, dtype = torch.float32)\n",
    "            yi = yi.to(device = device, dtype = torch.long)    \n",
    "            scores = model(xi)\n",
    "            # dim = 1 means we are taking the index of the max value in each row\n",
    "            _, preds = scores.max(dim=1)\n",
    "            # preds.shape => (mb_size,) yi.shape => (mb_size, 1)\n",
    "            num_correct += (preds == yi.squeeze()).sum()\n",
    "            # yi.size(0) is the number of elements in the batch\n",
    "            num_total += yi.size(0)\n",
    "        return float(num_correct) / num_total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, mb_size, verbose=False):\n",
    "    model= model.to(device = device)\n",
    "    acc = 0.0\n",
    "    epoch = 0\n",
    "    while acc<0.95:\n",
    "        model.train()\n",
    "        for (xi, yi) in create_minibatches(x_train_tensor, y_train_tensor, mb_size):\n",
    "            xi = xi.to(device = device, dtype = torch.float32)\n",
    "            yi = yi.to(device = device, dtype = torch.long)\n",
    "\n",
    "            scores = model(xi)\n",
    "            # cost function\n",
    "            cost = F.cross_entropy(input = scores, target = yi.squeeze())\n",
    "            optimizer.zero_grad()\n",
    "            cost.backward()\n",
    "            optimizer.step()\n",
    "        epoch += 1\n",
    "        acc = accuracy(model, x_val_tensor, y_val_tensor, mb_size)\n",
    "        print(f'Epoch: {epoch}, cost: {cost.item()}, accuracy: {acc}')\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost: 2.228043556213379, accuracy: 0.3737\n",
      "Epoch: 2, cost: 2.1458098888397217, accuracy: 0.5536\n",
      "Epoch: 3, cost: 2.045558214187622, accuracy: 0.6508\n",
      "Epoch: 4, cost: 1.9632009267807007, accuracy: 0.6999\n",
      "Epoch: 5, cost: 1.8318195343017578, accuracy: 0.7246\n",
      "Epoch: 6, cost: 1.7296510934829712, accuracy: 0.7505\n",
      "Epoch: 7, cost: 1.60267174243927, accuracy: 0.7684\n",
      "Epoch: 8, cost: 1.4676405191421509, accuracy: 0.7812\n",
      "Epoch: 9, cost: 1.3500102758407593, accuracy: 0.7935\n",
      "Epoch: 10, cost: 1.2159894704818726, accuracy: 0.8079\n",
      "Epoch: 11, cost: 1.1360201835632324, accuracy: 0.8206\n",
      "Epoch: 12, cost: 0.9914644956588745, accuracy: 0.8296\n",
      "Epoch: 13, cost: 1.0072038173675537, accuracy: 0.8385\n",
      "Epoch: 14, cost: 0.8766016960144043, accuracy: 0.8446\n",
      "Epoch: 15, cost: 0.864666759967804, accuracy: 0.8505\n",
      "Epoch: 16, cost: 0.7635716795921326, accuracy: 0.8551\n",
      "Epoch: 17, cost: 0.7305755615234375, accuracy: 0.8595\n",
      "Epoch: 18, cost: 0.7180152535438538, accuracy: 0.8638\n",
      "Epoch: 19, cost: 0.660862922668457, accuracy: 0.8675\n",
      "Epoch: 20, cost: 0.6375039219856262, accuracy: 0.8708\n",
      "Epoch: 21, cost: 0.6088647842407227, accuracy: 0.8753\n",
      "Epoch: 22, cost: 0.5865371823310852, accuracy: 0.8766\n",
      "Epoch: 23, cost: 0.5912915468215942, accuracy: 0.8795\n",
      "Epoch: 24, cost: 0.5966740846633911, accuracy: 0.8826\n",
      "Epoch: 25, cost: 0.5396328568458557, accuracy: 0.8831\n",
      "Epoch: 26, cost: 0.5304300785064697, accuracy: 0.8857\n",
      "Epoch: 27, cost: 0.512214183807373, accuracy: 0.8877\n",
      "Epoch: 28, cost: 0.49261417984962463, accuracy: 0.8896\n",
      "Epoch: 29, cost: 0.48572197556495667, accuracy: 0.8914\n",
      "Epoch: 30, cost: 0.4832548201084137, accuracy: 0.8927\n",
      "Epoch: 31, cost: 0.4731878936290741, accuracy: 0.8938\n",
      "Epoch: 32, cost: 0.4989948570728302, accuracy: 0.8964\n",
      "Epoch: 33, cost: 0.43428173661231995, accuracy: 0.8968\n",
      "Epoch: 34, cost: 0.416637659072876, accuracy: 0.8976\n",
      "Epoch: 35, cost: 0.45935893058776855, accuracy: 0.8987\n",
      "Epoch: 36, cost: 0.40278109908103943, accuracy: 0.8996\n",
      "Epoch: 37, cost: 0.4181484580039978, accuracy: 0.8997\n",
      "Epoch: 38, cost: 0.3809671700000763, accuracy: 0.9009\n",
      "Epoch: 39, cost: 0.43014732003211975, accuracy: 0.9018\n",
      "Epoch: 40, cost: 0.45023202896118164, accuracy: 0.9023\n",
      "Epoch: 41, cost: 0.40617677569389343, accuracy: 0.9026\n",
      "Epoch: 42, cost: 0.43540653586387634, accuracy: 0.903\n",
      "Epoch: 43, cost: 0.39355865120887756, accuracy: 0.9033\n",
      "Epoch: 44, cost: 0.38274192810058594, accuracy: 0.9044\n",
      "Epoch: 45, cost: 0.3799641728401184, accuracy: 0.9048\n",
      "Epoch: 46, cost: 0.3593347668647766, accuracy: 0.9055\n",
      "Epoch: 47, cost: 0.397382915019989, accuracy: 0.906\n",
      "Epoch: 48, cost: 0.3596847951412201, accuracy: 0.9062\n",
      "Epoch: 49, cost: 0.36808493733406067, accuracy: 0.9068\n",
      "Epoch: 50, cost: 0.40719887614250183, accuracy: 0.9075\n",
      "Epoch: 51, cost: 0.4014095067977905, accuracy: 0.9073\n",
      "Epoch: 52, cost: 0.36095166206359863, accuracy: 0.9079\n",
      "Epoch: 53, cost: 0.3168695271015167, accuracy: 0.909\n",
      "Epoch: 54, cost: 0.29600903391838074, accuracy: 0.9094\n",
      "Epoch: 55, cost: 0.35836535692214966, accuracy: 0.9091\n",
      "Epoch: 56, cost: 0.35150447487831116, accuracy: 0.9107\n",
      "Epoch: 57, cost: 0.3536987602710724, accuracy: 0.9103\n",
      "Epoch: 58, cost: 0.3757919371128082, accuracy: 0.912\n",
      "Epoch: 59, cost: 0.3286368250846863, accuracy: 0.9111\n",
      "Epoch: 60, cost: 0.3700726330280304, accuracy: 0.9116\n",
      "Epoch: 61, cost: 0.29873526096343994, accuracy: 0.9127\n",
      "Epoch: 62, cost: 0.3254627287387848, accuracy: 0.9126\n",
      "Epoch: 63, cost: 0.3679558336734772, accuracy: 0.9132\n",
      "Epoch: 64, cost: 0.3282686769962311, accuracy: 0.9136\n",
      "Epoch: 65, cost: 0.3769776225090027, accuracy: 0.9143\n",
      "Epoch: 66, cost: 0.3536032438278198, accuracy: 0.9146\n",
      "Epoch: 67, cost: 0.3190332353115082, accuracy: 0.9147\n",
      "Epoch: 68, cost: 0.3105211853981018, accuracy: 0.9148\n",
      "Epoch: 69, cost: 0.3223227262496948, accuracy: 0.9148\n",
      "Epoch: 70, cost: 0.33568957448005676, accuracy: 0.9154\n",
      "Epoch: 71, cost: 0.2850908637046814, accuracy: 0.9151\n",
      "Epoch: 72, cost: 0.36144137382507324, accuracy: 0.9152\n",
      "Epoch: 73, cost: 0.31768885254859924, accuracy: 0.9161\n",
      "Epoch: 74, cost: 0.3398696482181549, accuracy: 0.9161\n",
      "Epoch: 75, cost: 0.3154568672180176, accuracy: 0.916\n",
      "Epoch: 76, cost: 0.3428138792514801, accuracy: 0.9163\n",
      "Epoch: 77, cost: 0.2955828905105591, accuracy: 0.9169\n",
      "Epoch: 78, cost: 0.32782864570617676, accuracy: 0.9176\n",
      "Epoch: 79, cost: 0.3034513294696808, accuracy: 0.9182\n",
      "Epoch: 80, cost: 0.2870970368385315, accuracy: 0.9181\n",
      "Epoch: 81, cost: 0.3089142143726349, accuracy: 0.9191\n",
      "Epoch: 82, cost: 0.31022119522094727, accuracy: 0.9196\n",
      "Epoch: 83, cost: 0.3245903253555298, accuracy: 0.92\n",
      "Epoch: 84, cost: 0.3076738715171814, accuracy: 0.9206\n",
      "Epoch: 85, cost: 0.3118247389793396, accuracy: 0.92\n",
      "Epoch: 86, cost: 0.31785768270492554, accuracy: 0.9205\n",
      "Epoch: 87, cost: 0.2864701449871063, accuracy: 0.9205\n",
      "Epoch: 88, cost: 0.3252481520175934, accuracy: 0.9221\n",
      "Epoch: 89, cost: 0.316029816865921, accuracy: 0.9224\n",
      "Epoch: 90, cost: 0.2711333632469177, accuracy: 0.9227\n",
      "Epoch: 91, cost: 0.2743644416332245, accuracy: 0.9224\n",
      "Epoch: 92, cost: 0.29327213764190674, accuracy: 0.9231\n",
      "Epoch: 93, cost: 0.30194929242134094, accuracy: 0.9236\n",
      "Epoch: 94, cost: 0.3053815960884094, accuracy: 0.9241\n",
      "Epoch: 95, cost: 0.30063170194625854, accuracy: 0.9243\n",
      "Epoch: 96, cost: 0.2857024669647217, accuracy: 0.9244\n",
      "Epoch: 97, cost: 0.2545500695705414, accuracy: 0.9246\n",
      "Epoch: 98, cost: 0.2596140503883362, accuracy: 0.9247\n",
      "Epoch: 99, cost: 0.27527832984924316, accuracy: 0.9253\n",
      "Epoch: 100, cost: 0.29053062200546265, accuracy: 0.9254\n",
      "Epoch: 101, cost: 0.27652719616889954, accuracy: 0.9252\n",
      "Epoch: 102, cost: 0.299785852432251, accuracy: 0.9256\n",
      "Epoch: 103, cost: 0.26702243089675903, accuracy: 0.9264\n",
      "Epoch: 104, cost: 0.25703147053718567, accuracy: 0.9254\n",
      "Epoch: 105, cost: 0.30761393904685974, accuracy: 0.9259\n",
      "Epoch: 106, cost: 0.2592141628265381, accuracy: 0.9257\n",
      "Epoch: 107, cost: 0.2560897171497345, accuracy: 0.9261\n",
      "Epoch: 108, cost: 0.2871228754520416, accuracy: 0.9261\n",
      "Epoch: 109, cost: 0.25945714116096497, accuracy: 0.9257\n",
      "Epoch: 110, cost: 0.24163620173931122, accuracy: 0.9267\n",
      "Epoch: 111, cost: 0.28815406560897827, accuracy: 0.9269\n",
      "Epoch: 112, cost: 0.2709285318851471, accuracy: 0.9272\n",
      "Epoch: 113, cost: 0.2820613384246826, accuracy: 0.927\n",
      "Epoch: 114, cost: 0.2722819149494171, accuracy: 0.9275\n",
      "Epoch: 115, cost: 0.25900331139564514, accuracy: 0.9274\n",
      "Epoch: 116, cost: 0.2972910404205322, accuracy: 0.9282\n",
      "Epoch: 117, cost: 0.26926031708717346, accuracy: 0.9273\n",
      "Epoch: 118, cost: 0.26769712567329407, accuracy: 0.9274\n",
      "Epoch: 119, cost: 0.2567562162876129, accuracy: 0.9277\n",
      "Epoch: 120, cost: 0.28612470626831055, accuracy: 0.9284\n",
      "Epoch: 121, cost: 0.2793731987476349, accuracy: 0.9285\n",
      "Epoch: 122, cost: 0.26606929302215576, accuracy: 0.9286\n",
      "Epoch: 123, cost: 0.2714898884296417, accuracy: 0.9289\n",
      "Epoch: 124, cost: 0.27845725417137146, accuracy: 0.9296\n",
      "Epoch: 125, cost: 0.2829664647579193, accuracy: 0.9295\n",
      "Epoch: 126, cost: 0.24367935955524445, accuracy: 0.9297\n",
      "Epoch: 127, cost: 0.2870014011859894, accuracy: 0.9299\n",
      "Epoch: 128, cost: 0.2839219570159912, accuracy: 0.9301\n",
      "Epoch: 129, cost: 0.2298392951488495, accuracy: 0.9301\n",
      "Epoch: 130, cost: 0.30088233947753906, accuracy: 0.9308\n",
      "Epoch: 131, cost: 0.20935165882110596, accuracy: 0.9308\n",
      "Epoch: 132, cost: 0.26560404896736145, accuracy: 0.9312\n",
      "Epoch: 133, cost: 0.2601747512817383, accuracy: 0.9309\n",
      "Epoch: 134, cost: 0.2551132142543793, accuracy: 0.9321\n",
      "Epoch: 135, cost: 0.22165393829345703, accuracy: 0.9316\n",
      "Epoch: 136, cost: 0.2321704775094986, accuracy: 0.9316\n",
      "Epoch: 137, cost: 0.24970632791519165, accuracy: 0.932\n",
      "Epoch: 138, cost: 0.22630654275417328, accuracy: 0.9321\n",
      "Epoch: 139, cost: 0.234750896692276, accuracy: 0.9318\n",
      "Epoch: 140, cost: 0.24228554964065552, accuracy: 0.933\n",
      "Epoch: 141, cost: 0.2257203310728073, accuracy: 0.9328\n",
      "Epoch: 142, cost: 0.26428380608558655, accuracy: 0.9334\n",
      "Epoch: 143, cost: 0.2691054940223694, accuracy: 0.9335\n",
      "Epoch: 144, cost: 0.23107148706912994, accuracy: 0.9339\n",
      "Epoch: 145, cost: 0.2711799144744873, accuracy: 0.9339\n",
      "Epoch: 146, cost: 0.23916484415531158, accuracy: 0.9341\n",
      "Epoch: 147, cost: 0.23942740261554718, accuracy: 0.9346\n",
      "Epoch: 148, cost: 0.2349383533000946, accuracy: 0.9348\n",
      "Epoch: 149, cost: 0.2625788450241089, accuracy: 0.9342\n",
      "Epoch: 150, cost: 0.25847089290618896, accuracy: 0.9347\n",
      "Epoch: 151, cost: 0.25109535455703735, accuracy: 0.9351\n",
      "Epoch: 152, cost: 0.2555071711540222, accuracy: 0.9344\n",
      "Epoch: 153, cost: 0.23101884126663208, accuracy: 0.9353\n",
      "Epoch: 154, cost: 0.22320441901683807, accuracy: 0.9356\n",
      "Epoch: 155, cost: 0.21068792045116425, accuracy: 0.9354\n",
      "Epoch: 156, cost: 0.26020610332489014, accuracy: 0.9361\n",
      "Epoch: 157, cost: 0.20857127010822296, accuracy: 0.9355\n",
      "Epoch: 158, cost: 0.22038806974887848, accuracy: 0.9355\n",
      "Epoch: 159, cost: 0.23150722682476044, accuracy: 0.9361\n",
      "Epoch: 160, cost: 0.23494550585746765, accuracy: 0.9364\n",
      "Epoch: 161, cost: 0.2064206302165985, accuracy: 0.9365\n",
      "Epoch: 162, cost: 0.23137688636779785, accuracy: 0.9363\n",
      "Epoch: 163, cost: 0.2087242752313614, accuracy: 0.937\n",
      "Epoch: 164, cost: 0.22730089724063873, accuracy: 0.9367\n",
      "Epoch: 165, cost: 0.23633551597595215, accuracy: 0.9372\n",
      "Epoch: 166, cost: 0.23893867433071136, accuracy: 0.9373\n",
      "Epoch: 167, cost: 0.20300732553005219, accuracy: 0.9372\n",
      "Epoch: 168, cost: 0.24195149540901184, accuracy: 0.9375\n",
      "Epoch: 169, cost: 0.22645488381385803, accuracy: 0.9381\n",
      "Epoch: 170, cost: 0.2333160936832428, accuracy: 0.9382\n",
      "Epoch: 171, cost: 0.21885453164577484, accuracy: 0.9375\n",
      "Epoch: 172, cost: 0.1920662522315979, accuracy: 0.9385\n",
      "Epoch: 173, cost: 0.23790360987186432, accuracy: 0.9391\n",
      "Epoch: 174, cost: 0.18069466948509216, accuracy: 0.9392\n",
      "Epoch: 175, cost: 0.23230648040771484, accuracy: 0.9388\n",
      "Epoch: 176, cost: 0.1808379590511322, accuracy: 0.9389\n",
      "Epoch: 177, cost: 0.18483829498291016, accuracy: 0.9386\n",
      "Epoch: 178, cost: 0.23851466178894043, accuracy: 0.9405\n",
      "Epoch: 179, cost: 0.23943264782428741, accuracy: 0.9395\n",
      "Epoch: 180, cost: 0.24174247682094574, accuracy: 0.9398\n",
      "Epoch: 181, cost: 0.21550023555755615, accuracy: 0.9406\n",
      "Epoch: 182, cost: 0.22448235750198364, accuracy: 0.9407\n",
      "Epoch: 183, cost: 0.15986815094947815, accuracy: 0.9414\n",
      "Epoch: 184, cost: 0.24171553552150726, accuracy: 0.9411\n",
      "Epoch: 185, cost: 0.23922626674175262, accuracy: 0.9412\n",
      "Epoch: 186, cost: 0.25359010696411133, accuracy: 0.9408\n",
      "Epoch: 187, cost: 0.22171659767627716, accuracy: 0.9419\n",
      "Epoch: 188, cost: 0.21709753572940826, accuracy: 0.9422\n",
      "Epoch: 189, cost: 0.20636050403118134, accuracy: 0.9424\n",
      "Epoch: 190, cost: 0.17699608206748962, accuracy: 0.9418\n",
      "Epoch: 191, cost: 0.2269720733165741, accuracy: 0.9424\n",
      "Epoch: 192, cost: 0.22148121893405914, accuracy: 0.9425\n",
      "Epoch: 193, cost: 0.23270846903324127, accuracy: 0.9425\n",
      "Epoch: 194, cost: 0.21087613701820374, accuracy: 0.9431\n",
      "Epoch: 195, cost: 0.1983620822429657, accuracy: 0.9419\n",
      "Epoch: 196, cost: 0.19244396686553955, accuracy: 0.9437\n",
      "Epoch: 197, cost: 0.21112799644470215, accuracy: 0.9442\n",
      "Epoch: 198, cost: 0.22151488065719604, accuracy: 0.9441\n",
      "Epoch: 199, cost: 0.18307501077651978, accuracy: 0.9441\n",
      "Epoch: 200, cost: 0.2690223157405853, accuracy: 0.9444\n",
      "Epoch: 201, cost: 0.21814808249473572, accuracy: 0.944\n",
      "Epoch: 202, cost: 0.22856003046035767, accuracy: 0.9447\n",
      "Epoch: 203, cost: 0.21176858246326447, accuracy: 0.9445\n",
      "Epoch: 204, cost: 0.20354029536247253, accuracy: 0.9449\n",
      "Epoch: 205, cost: 0.18190790712833405, accuracy: 0.9452\n",
      "Epoch: 206, cost: 0.2091803103685379, accuracy: 0.9446\n",
      "Epoch: 207, cost: 0.20062293112277985, accuracy: 0.9459\n",
      "Epoch: 208, cost: 0.23469161987304688, accuracy: 0.9465\n",
      "Epoch: 209, cost: 0.20608700811862946, accuracy: 0.9456\n",
      "Epoch: 210, cost: 0.20138627290725708, accuracy: 0.9467\n",
      "Epoch: 211, cost: 0.19958722591400146, accuracy: 0.9471\n",
      "Epoch: 212, cost: 0.186054065823555, accuracy: 0.9471\n",
      "Epoch: 213, cost: 0.23717519640922546, accuracy: 0.9472\n",
      "Epoch: 214, cost: 0.17625194787979126, accuracy: 0.9466\n",
      "Epoch: 215, cost: 0.24668970704078674, accuracy: 0.9472\n",
      "Epoch: 216, cost: 0.22283326089382172, accuracy: 0.9473\n",
      "Epoch: 217, cost: 0.1881784349679947, accuracy: 0.9471\n",
      "Epoch: 218, cost: 0.16597837209701538, accuracy: 0.9472\n",
      "Epoch: 219, cost: 0.22186937928199768, accuracy: 0.9475\n",
      "Epoch: 220, cost: 0.22737595438957214, accuracy: 0.9475\n",
      "Epoch: 221, cost: 0.17330551147460938, accuracy: 0.9478\n",
      "Epoch: 222, cost: 0.21464303135871887, accuracy: 0.9479\n",
      "Epoch: 223, cost: 0.16339527070522308, accuracy: 0.9477\n",
      "Epoch: 224, cost: 0.22315332293510437, accuracy: 0.9479\n",
      "Epoch: 225, cost: 0.17351660132408142, accuracy: 0.9481\n",
      "Epoch: 226, cost: 0.21857158839702606, accuracy: 0.9482\n",
      "Epoch: 227, cost: 0.22901111841201782, accuracy: 0.9482\n",
      "Epoch: 228, cost: 0.16017723083496094, accuracy: 0.9484\n",
      "Epoch: 229, cost: 0.23367826640605927, accuracy: 0.9487\n",
      "Epoch: 230, cost: 0.17304356396198273, accuracy: 0.9493\n",
      "Epoch: 231, cost: 0.2235487699508667, accuracy: 0.949\n",
      "Epoch: 232, cost: 0.18344256281852722, accuracy: 0.9493\n",
      "Epoch: 233, cost: 0.20192311704158783, accuracy: 0.9496\n",
      "Epoch: 234, cost: 0.20163775980472565, accuracy: 0.9496\n",
      "Epoch: 235, cost: 0.22720876336097717, accuracy: 0.9498\n",
      "Epoch: 236, cost: 0.20614202320575714, accuracy: 0.9499\n",
      "Epoch: 237, cost: 0.2154744565486908, accuracy: 0.9494\n",
      "Epoch: 238, cost: 0.21704991161823273, accuracy: 0.9498\n",
      "Epoch: 239, cost: 0.216508150100708, accuracy: 0.9496\n",
      "Epoch: 240, cost: 0.1708667129278183, accuracy: 0.9501\n",
      "with learning rate 0.01 the accuracy is 0.9501\n"
     ]
    }
   ],
   "source": [
    "hidden1 = 1000\n",
    "hidden2 = 1000\n",
    "mb_size = 4096\n",
    "lr = 1e-2\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model1 = nn.Sequential(\n",
    "    nn.Linear(in_features=784, out_features=hidden1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features =hidden1, out_features=hidden2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=hidden2, out_features=10)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr = lr)\n",
    "train(model1, optimizer, mb_size)\n",
    "acc = accuracy(model1, x_val_tensor, y_val_tensor, mb_size)\n",
    "print(f'with learning rate {lr} the accuracy is {acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost: 1.9743847846984863, accuracy: 0.7267\n",
      "Epoch: 2, cost: 1.1435048580169678, accuracy: 0.8047\n",
      "Epoch: 3, cost: 0.658129870891571, accuracy: 0.8617\n",
      "Epoch: 4, cost: 0.4779020845890045, accuracy: 0.8849\n",
      "Epoch: 5, cost: 0.3703247904777527, accuracy: 0.8994\n",
      "Epoch: 6, cost: 0.3556472957134247, accuracy: 0.9045\n",
      "Epoch: 7, cost: 0.27768367528915405, accuracy: 0.9095\n",
      "Epoch: 8, cost: 0.2843078076839447, accuracy: 0.9144\n",
      "Epoch: 9, cost: 0.29759088158607483, accuracy: 0.9177\n",
      "Epoch: 10, cost: 0.3479636609554291, accuracy: 0.9212\n",
      "Epoch: 11, cost: 0.2946082651615143, accuracy: 0.9247\n",
      "Epoch: 12, cost: 0.25849252939224243, accuracy: 0.9272\n",
      "Epoch: 13, cost: 0.26719361543655396, accuracy: 0.9289\n",
      "Epoch: 14, cost: 0.27311399579048157, accuracy: 0.9301\n",
      "Epoch: 15, cost: 0.2668359577655792, accuracy: 0.9323\n",
      "Epoch: 16, cost: 0.19098392128944397, accuracy: 0.9339\n",
      "Epoch: 17, cost: 0.25633513927459717, accuracy: 0.9363\n",
      "Epoch: 18, cost: 0.20688194036483765, accuracy: 0.9373\n",
      "Epoch: 19, cost: 0.22572016716003418, accuracy: 0.9387\n",
      "Epoch: 20, cost: 0.2383245825767517, accuracy: 0.9415\n",
      "Epoch: 21, cost: 0.2335217148065567, accuracy: 0.9435\n",
      "Epoch: 22, cost: 0.18728530406951904, accuracy: 0.9447\n",
      "Epoch: 23, cost: 0.18373240530490875, accuracy: 0.947\n",
      "Epoch: 24, cost: 0.15253056585788727, accuracy: 0.9471\n",
      "Epoch: 25, cost: 0.15984514355659485, accuracy: 0.949\n",
      "Epoch: 26, cost: 0.1820206493139267, accuracy: 0.9508\n",
      "with learning rate 0.01 the accuracy is 0.9508\n"
     ]
    }
   ],
   "source": [
    "hidden1 = 1000\n",
    "hidden2 = 1000\n",
    "mb_size = 4096\n",
    "lr = 1e-2\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model2 = nn.Sequential(\n",
    "    nn.Linear(in_features=784, out_features=hidden1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features =hidden1, out_features=hidden2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=hidden2, out_features=10)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr = lr, momentum=0.9)\n",
    "train(model2, optimizer, mb_size)\n",
    "acc = accuracy(model2, x_val_tensor, y_val_tensor, mb_size)\n",
    "print(f'with learning rate {lr} the accuracy is {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost: 1.102938175201416, accuracy: 0.7574\n",
      "Epoch: 2, cost: 0.5033108592033386, accuracy: 0.8787\n",
      "Epoch: 3, cost: 0.3034345209598541, accuracy: 0.9252\n",
      "Epoch: 4, cost: 0.21724681556224823, accuracy: 0.9275\n",
      "Epoch: 5, cost: 0.6248605847358704, accuracy: 0.8532\n",
      "Epoch: 6, cost: 0.20916250348091125, accuracy: 0.9523\n",
      "with learning rate 0.01 the accuracy is 0.9523\n"
     ]
    }
   ],
   "source": [
    "hidden1 = 1000\n",
    "hidden2 = 1000\n",
    "mb_size = 4096\n",
    "lr = 1e-2\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model3 = nn.Sequential(\n",
    "    nn.Linear(in_features=784, out_features=hidden1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features =hidden1, out_features=hidden2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=hidden2, out_features=10)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model3.parameters(), lr = lr, alpha=0.9)\n",
    "train(model3, optimizer, mb_size)\n",
    "acc = accuracy(model3, x_val_tensor, y_val_tensor, mb_size)\n",
    "print(f'with learning rate {lr} the accuracy is {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost: 0.8015338778495789, accuracy: 0.7952\n",
      "Epoch: 2, cost: 0.27738553285598755, accuracy: 0.9261\n",
      "Epoch: 3, cost: 0.17302459478378296, accuracy: 0.95\n",
      "with learning rate 0.01 the accuracy is 0.95\n"
     ]
    }
   ],
   "source": [
    "hidden1 = 1000\n",
    "hidden2 = 1000\n",
    "mb_size = 4096\n",
    "lr = 1e-2\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model4 = nn.Sequential(\n",
    "    nn.Linear(in_features=784, out_features=hidden1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features =hidden1, out_features=hidden2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=hidden2, out_features=10)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr = lr, betas= (0.9, 0.999))\n",
    "train(model4, optimizer, mb_size)\n",
    "acc = accuracy(model4, x_val_tensor, y_val_tensor, mb_size)\n",
    "print(f'with learning rate {lr} the accuracy is {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entornoJupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
